{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Script (Extractions) for Inpatient Envelope - GBD 2020\n",
    "### Survey Extraction, Data Processing, Admin Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where your code lives\n",
    "home_dir = 'FILEPATH'\n",
    "# your project\n",
    "proj = 'proj_hospital'\n",
    "# where you want data written\n",
    "write_dir ='FILEPATH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "\n",
    "import requests\n",
    "import copy as copy\n",
    "import glob as glob\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from extractor import gdoc_query, extractor\n",
    "from db_queries import get_population, get_covariate_estimates, get_model_results\n",
    "from functions_to_prep_extractions import *\n",
    "from cluster_utilities import *\n",
    "from elmo import run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and prep data for extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in ALL extraction templates - new and old\n",
    "# Custom function - see extractor.py\n",
    "\n",
    "# Oldest extractions - \"Pre GBD 2017\"\n",
    "pre_gbd_2017 = gdoc_query('FILEPATH')\n",
    "\n",
    "# GBD 2017 extractions\n",
    "new_extraction = gdoc_query('FILEPATH')\n",
    "# indonesia subnational\n",
    "idn_sub = gdoc_query('FILEPATH')\n",
    "# india subnational\n",
    "#ind_sub = gdoc_query('FILEPATH')\n",
    "# WHO MCCS\n",
    "mccs = gdoc_query('FILEPATH')\n",
    "# world health survey\n",
    "whs = gdoc_query('FILEPATH')\n",
    "# world bank\n",
    "wb = gdoc_query('FILEPATH')\n",
    "# mexico subnational\n",
    "mex_2006 = gdoc_query('FILEPATH')\n",
    "# brazil data\n",
    "bra = gdoc_query('FILEPATH')\n",
    "\n",
    "# Testing\n",
    "#tester = gdoc_query('FILEPATH')\n",
    "\n",
    "# Full 2020 Extraction Sheets\n",
    "all_2020_extractions = gdoc_query('FILEPATH')\n",
    "india_2020 = gdoc_query('FILEPATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all data from above\n",
    "df_reader = pd.concat([pre_gbd_2017,new_extraction,idn_sub,mccs,whs,wb,mex_2006,bra,all_2020_extractions,india_2020], \n",
    "                      sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peek at your data\n",
    "df_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP FOLDERS FOR EXTRACTED RAW DATA\n",
    "# Removes file if it already exists\n",
    "!rm -r FILEPATH\n",
    "\n",
    "# Creates new file\n",
    "!mkdir FILEPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for INPATIENT extractions only\n",
    "df_reader = df_reader.loc[df_reader.type.isin(['ip'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df_reader = df_reader.loc[~df_reader.unique_id.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df_reader = df_reader.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv file \n",
    "df_reader.reset_index(drop=True).to_csv(write_dir+'inpatient_template_reader.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelize survey extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Submit extraction jobs for each survey in df_reader\n",
    "os.chdir(home_dir)\n",
    "for i in np.arange((len(df_reader))):\n",
    "    name_arg = 'extraction_' + str(i) + '_job'\n",
    "    call = qsub(1, 9, name_arg, home_dir + 'ip_extraction_code.py',\n",
    "           project = proj,\n",
    "           script_args = [home_dir, write_dir, str(i), proj])\n",
    "    call = \" \".join(call)\n",
    "    #print(call)\n",
    "    os.system(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see which survey extractions broke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure I got all of them \n",
    "files = os.listdir(write_dir)\n",
    "files = [x for x in files if ('num_visit' in x) | ('util_var' in x)]\n",
    "\n",
    "# check to see which surveys failed\n",
    "for y in df_reader.unique_id.unique():\n",
    "    if len([x for x in files if str(y).lower() in x]) != 0:\n",
    "        pass\n",
    "    else:\n",
    "        print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to help locate extraction number, i (index) by NID\n",
    "df_reader.loc[df_reader.nid == '151719']\n",
    "# if above doesn't work, try NID as a string instead:\n",
    "# i.e. df_reader.loc[df_reader.nid == '157635']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run a single index (if needed)\n",
    "i = 1202\n",
    "name_arg = 'extraction_' + str(i) + '_job'\n",
    "call = qsub(1,9,name_arg, home_dir + 'ip_extraction_code.py',\n",
    "        project = proj,\n",
    "        script_args = [home_dir, write_dir, str(i), proj], o = True)\n",
    "call = \" \".join(call)\n",
    "#print(call)\n",
    "os.system(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile all surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compile_survey_data, see functions_to_prep_extractions.py\n",
    "num_visit, fraction = compile_survey_data().compile_survey_data(df_reader = df_reader, \n",
    "             recall_rules = {4.3: [0,29.1],\n",
    "                      52. :[29.1, 999]},\n",
    "               path = write_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect surveys by type - either num_visit or fraction\n",
    "data = {'num_visit':num_visit, 'fraction':fraction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.keys():\n",
    "    temp = data[i]\n",
    "    temp.loc[temp.location_id == 95, 'location_id'] = 4749\n",
    "    temp.rename(columns = {'filepath': 'unique_id'}, inplace = True)\n",
    "    \n",
    "    # replace zero with tiny number\n",
    "    temp.loc[temp['mean'] == 0, 'mean'] = .001\n",
    "    \n",
    "    ## print number of values below zero\n",
    "    print(len(temp[temp['mean'] < 0]))\n",
    "    temp = prep_upload(temp.copy(), recall_rules = {'cv_1_month_recall':[0, 29.1],\n",
    "                                                    'cv_12_month_recall':[29.1, 999.]})\n",
    "    temp['cv_marketscan'] = 0\n",
    "    temp['cv_whs'] = 0\n",
    "    temp['is_outlier'] = 0\n",
    "    temp['cv_survey'] = 1\n",
    "    temp['cv_whs'] = 0\n",
    "    temp['cv_mics'] = 0\n",
    "    data[i] = temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data frames for separate survey types \n",
    "fraction = data['fraction']\n",
    "num_visit = data['num_visit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in admin/facility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in reported data\n",
    "reported = pd.read_csv('FILEPATH')\n",
    "\n",
    "reported['cv_survey'] = 0\n",
    "reported['cv_1_month_recall'] = 0\n",
    "reported['cv_12_month_recall'] = 0\n",
    "reported['cv_marketscan'] = 0\n",
    "reported['cv_whs'] = 0\n",
    "\n",
    "reported['nid'] = pd.to_numeric(reported['nid'], downcast = 'float')\n",
    "reported['is_outlier'] = 0\n",
    "reported['visit_type'] = 'ip'\n",
    "\n",
    "reported = reported.loc[['BRA' not in x for x in tabs.ihme_loc_id.tolist()]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate sources between \"reported\" file and clinical sources extracted\n",
    "dup_nids = (3822,86886,86887,86888,86889,86890,86891,86892,86893,86894,86895,86896,86897,86898,86899,86900,\n",
    "            86901,86902,86903,86904,86905,86906,86907,86908,86909,86910,86911,86912,86913,86914,86915,86916,\n",
    "            86917,86997,86998,86999,87000,87001,87002,87003,87004,87005,87006,87007,87008,87009,87010,87011,\n",
    "            90314,90315,90316,90317,90318,90319,90322,114876,121334,121405,121424,121425,121917,149501,149502,\n",
    "            149503,149504,160484,205019,220786,220787,220788,220789,220790,220791,220792,220793,220794,220795,\n",
    "            220796,220797,220798,220799,220800,237756,239353,293984)\n",
    "reported = reported[~reported.nid.isin(dup_nids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure those sources actually dropped \n",
    "reported.nid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facility data \n",
    "fac_data = pd.read_csv('FILEPATH')\n",
    "fac_data['is_outlier'] = 0\n",
    "fac_data['cv_survey'] = 0\n",
    "fac_data['cv_1_month_recall'] = 0\n",
    "fac_data['cv_12_month_recall'] = 0\n",
    "fac_data['cv_marketscan'] = 0\n",
    "fac_data['cv_whs'] = 0\n",
    "fac_data['visit_type'] = 'ip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Older sources that are extracted as both sex, 0-100 age group - not great data \n",
    "fac_data = fac_data[fac_data.nid != 299087]\n",
    "fac_data = fac_data[fac_data.nid != 299088]\n",
    "fac_data = fac_data[fac_data.nid != 299089]\n",
    "fac_data = fac_data[fac_data.nid != 299090]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabulated data \n",
    "tabs = pd.read_csv('FILEPATH')\n",
    "tabs = tabs.loc[tabs.visit_type.isin(['ip_avg', 'ip_frac'])]\n",
    "tabs['cv_marketscan'] = 0\n",
    "tabs['cv_whs'] = 0\n",
    "tabs['is_outlier'] = 0\n",
    "tabs['cv_survey'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in re-extracted and newly extracted hospital/inpatient admin data for 2020\n",
    "path = 'FILEPATH'                   \n",
    "all_files = glob.glob(os.path.join(path, '*.csv'))     \n",
    "ip_new_2020 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "ip_new_2020['is_outlier'] = 0\n",
    "ip_new_2020['cv_survey'] = 0\n",
    "ip_new_2020['cv_1_month_recall'] = 0\n",
    "ip_new_2020['cv_12_month_recall'] = 0\n",
    "ip_new_2020['cv_marketscan'] = 0\n",
    "ip_new_2020['cv_whs'] = 0\n",
    "ip_new_2020['visit_type'] = 'ip'\n",
    "ip_new_2020.loc[ip_new_2020['sex_id'] == 1, \"sex\"] = 'Male'\n",
    "ip_new_2020.loc[ip_new_2020['sex_id'] == 2, \"sex\"] = 'Female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time scale adjustment for under 1 age groups\n",
    "ip_new_2020.loc[ip_new_2020['age_group_id'] == 2, 'mean'] = ip_new_2020['mean']/(365/7)\n",
    "ip_new_2020.loc[ip_new_2020['age_group_id'] == 3, 'mean'] = ip_new_2020['mean']/(365/21)\n",
    "ip_new_2020.loc[ip_new_2020['age_group_id'] == 388, 'mean'] = ip_new_2020['mean']/(365/154)\n",
    "ip_new_2020.loc[ip_new_2020['age_group_id'] == 389, 'mean'] = ip_new_2020['mean']/(365/183)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taiwan data\n",
    "twn = pd.read_csv('FILEPATH')\n",
    "twn['nid'] = 336203\n",
    "twn['location_id'] = 8\n",
    "twn['mean'] = pd.to_numeric(twn['val'])/pd.to_numeric(twn['pop'])\n",
    "twn.rename(columns={'pop':'sample_size'}, inplace=True)\n",
    "twn['cases'] = twn['val']\n",
    "twn['lower'] = ''\n",
    "twn['upper'] = ''\n",
    "twn['standard_error'] = ''\n",
    "twn['year_start'] = 2016\n",
    "twn['year_end'] = 2016\n",
    "twn = calc_se(twn.copy()).calc_se()\n",
    "twn['is_outlier'] = 0\n",
    "twn['visit_type'] = 'ip'\n",
    "twn['cv_survey'] = 0\n",
    "twn['cv_1_month_recall'] = 0\n",
    "twn['cv_12_month_recall'] = 0\n",
    "twn['cv_marketscan'] = 0\n",
    "twn['cv_whs'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HCUP NIS data\n",
    "nis = pd.read_csv('FILEPATH')\n",
    "nis.rename(columns={'env':'mean'}, inplace=True)\n",
    "nis.rename(columns={'population':'sample_size'}, inplace=True)\n",
    "nis['cases'] = nis['admits']\n",
    "nis['lower'] = ''\n",
    "nis['upper'] = ''\n",
    "nis['standard_error'] = ''\n",
    "nis['year_start'] = nis['year_id']\n",
    "nis['year_end'] = nis['year_id']\n",
    "nis = calc_se(nis.copy()).calc_se()\n",
    "nis['is_outlier'] = 0\n",
    "nis['visit_type'] = 'ip'\n",
    "nis['cv_survey'] = 0\n",
    "nis['cv_1_month_recall'] = 0\n",
    "nis['cv_12_month_recall'] = 0\n",
    "nis['cv_marketscan'] = 0\n",
    "nis['cv_whs'] = 0\n",
    "nis.loc[nis['sex_id'] == 1, \"sex\"] = 'Male'\n",
    "nis.loc[nis['sex_id'] == 2, \"sex\"] = 'Female'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up for combining all data\n",
    "all_cols = [] \n",
    "collect_data_all = pd.DataFrame()\n",
    "dict_of_dfs = {'fracs_survey':fraction,\n",
    "              'avg_survey':num_visit,\n",
    "              'tabs':tabs,\n",
    "              'reported':reported,\n",
    "              'fac_data':fac_data,\n",
    "              'ip_new_2020':ip_new_2020,\n",
    "              'twn':twn,\n",
    "              'nis':nis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all data\n",
    "for i in dict_of_dfs.keys():\n",
    "    print(i)\n",
    "    print(len(dict_of_dfs[i]))\n",
    "    all_cols.extend(dict_of_dfs[i].columns.tolist())\n",
    "    dict_of_dfs[i]['data_file'] = i\n",
    "    dict_of_dfs[i]['sex'] = dict_of_dfs[i]['sex'].str.lower()\n",
    "    collect_data_all = collect_data_all.append(dict_of_dfs[i])\n",
    "collect_data_all.loc[collect_data_all.visit_type == 'ip', 'cv_12_month_recall'] = 1\n",
    "collect_data_all.loc[collect_data_all.visit_type == 'ip', 'visit_type'] = 'ip_avg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data_all.loc[collect_data_all['age_group_id'] == 1, 'age_group_id'] = None\n",
    "collect_data_all.loc[collect_data_all['age_group_id'] == 4, 'age_group_id'] = None\n",
    "collect_data_all.loc[collect_data_all['age_group_id'] == 5, 'age_group_id'] = None\n",
    "collect_data_all.loc[collect_data_all['age_group_id'] == 8, 'age_group_id'] = None\n",
    "collect_data_all.loc[collect_data_all['age_group_id'] == 22, 'age_group_id'] = None\n",
    "collect_data_all.loc[collect_data_all['age_group_id'] == 28, 'age_group_id'] = None\n",
    "collect_data_all.loc[collect_data_all['age_group_id'] == 294, 'age_group_id'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data_all.age_group_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleanup pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust wrong iso code for romania\n",
    "collect_data_all.loc[collect_data_all.ihme_loc_id == 'ROM', 'location_id'] = 52\n",
    "collect_data_all.loc[collect_data_all.ihme_loc_id == 'ROM', 'ihme_loc_id'] = 'ROU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with no outliers\n",
    "# modeling in 'continuous'\n",
    "collect_data_all['is_outlier'] = 0\n",
    "collect_data_all['measure'] = 'continuous'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure no blanks\n",
    "try:\n",
    "    print(len(collect_data_all.loc[collect_data_all.location_id == '']))\n",
    "    collect_data_all = collect_data_all.loc[collect_data_all.location_id != '']\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert nids to numerics\n",
    "collect_data_all['location_id'] = pd.to_numeric(collect_data_all['location_id'])\n",
    "collect_data_all['nid'] = pd.to_numeric(collect_data_all['nid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier Alaska admin data\n",
    "collect_data_all.loc[collect_data_all['location_name'] == 'Alaska', 'is_outlier'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers not consistent with other data - don't want to process\n",
    "collect_data_all.loc[(collect_data_all.nid == 112332) & (collect_data_all.sex == 'Female'), 'is_outlier'] = 1\n",
    "collect_data_all.loc[(collect_data_all.nid == 20596) & (collect_data_all.sex == 'Female'), 'is_outlier'] = 1\n",
    "collect_data_all.loc[(collect_data_all.ihme_loc_id == 'BIH') & (collect_data_all['mean'] >.5) & (collect_data_all.year_start == 2004), 'is_outlier'] = 1\n",
    "collect_data_all.loc[collect_data_all.nid == 307778, 'is_outlier'] = 1\n",
    "collect_data_all.loc[collect_data_all.nid == 138595, 'is_outlier'] = 1\n",
    "collect_data_all.loc[(collect_data_all.location_id == 20) & (collect_data_all.year_start == 2002) & (collect_data_all.nid != 310156), 'is_outlier'] = 1\n",
    "collect_data_all.loc[(collect_data_all.location_id == 180) & (collect_data_all.year_start == 2003) & (collect_data_all.nid != 310156), 'is_outlier'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBR correct duplicate in lower uk levels\n",
    "uk = collect_data_all.loc[collect_data_all.location_id == 95]\n",
    "collect_data_all = collect_data_all.loc[collect_data_all.location_id != 95]\n",
    "uk1 = uk.copy()\n",
    "uk2 = uk.copy()\n",
    "uk3 = uk.copy()\n",
    "uk4 = uk.copy()\n",
    "uk1['location_id'] = 4749 \n",
    "uk2['location_id'] = 4636\n",
    "uk3['location_id'] = 434\n",
    "uk4['location_id'] = 433\n",
    "uk = pd.concat((uk1, uk2, uk3, uk4))\n",
    "collect_data_all = pd.concat((collect_data_all, uk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.read_excel('FILEPATH').columns\n",
    "cols = [x for x in cols if '.1' not in x]\n",
    "cols.extend(['cv_12_month_recall', 'cv_survey', 'cv_1_month_recall', 'data_file', 'cv_sick','cv_mics', 'cv_whs', 'cv_marketscan', 'unique_id', 'true_recall'])            \n",
    "cols = list(set(cols))\n",
    "collect_data_all = collect_data_all[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these are numerics\n",
    "collect_data_all['year_start'] = pd.to_numeric(collect_data_all['year_start'])\n",
    "collect_data_all['year_end'] = pd.to_numeric(collect_data_all['year_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data_all.loc[collect_data_all.year_start >= collect_data_all.year_end, 'year_start'] = collect_data_all.loc[collect_data_all.year_start >= collect_data_all.year_end, 'year_end']-1\n",
    "collect_data_all['unit_value_as_published'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SE where it is missing (i.e. surveys)\n",
    "collect_data_all = calc_se(collect_data_all.copy()).calc_se()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows\n",
    "collect_data_all = collect_data_all.drop(columns = ['index'])\n",
    "collect_data_all = collect_data_all.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save here so don't have to re-run whole script when debugging\n",
    "collect_data_all.to_csv('FILEPATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN THIS CELL IF NEEDED\n",
    "#collect_data_all = pd.read_csv('FILEPATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any data types with 1-mo. recall & ip_avg (probably not)\n",
    "len_check = len(collect_data_all.loc[((collect_data_all.visit_type == 'ip_avg') & (collect_data_all.cv_1_month_recall == 1))])\n",
    "\n",
    "# if there are any of these, remove them\n",
    "collect_data_all = collect_data_all.loc[~((collect_data_all.visit_type == 'ip_avg') & (collect_data_all.cv_1_month_recall == 1))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when surveys report average and fractions, only keep average data \n",
    "num_visit_loc_ids = num_visit.unique_id.unique().tolist()\n",
    "print(len(collect_data_all.loc[((collect_data_all.data_file == 'fracs_survey') & (collect_data_all.unique_id.isin(num_visit_loc_ids)))]))\n",
    "collect_data_all = collect_data_all.loc[~((collect_data_all.data_file == 'fracs_survey') & (collect_data_all.unique_id.isin(num_visit_loc_ids)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge on age_group_ids for data in correct age groups\n",
    "# Read in age group metadata file\n",
    "age_group_ids = pd.read_csv('FILEPATH')\n",
    "# Rename columns to match collect_data_all names\n",
    "age_group_ids = age_group_ids.rename(columns={'age_group_years_start':'age_start','age_group_years_end':'age_end'})\n",
    "# Merge but make sure to keep all rows from collect_data_all\n",
    "collect_data_all = pd.merge(collect_data_all, age_group_ids, on=['age_start', 'age_end'], how='left')\n",
    "# Drop columns not needed\n",
    "collect_data_all = collect_data_all.drop(columns=['age_group_name'])\n",
    "# Clean up all columns\n",
    "collect_data_all = collect_data_all[[\"nid\",\"data_file\",\"unique_id\",\"location_name\",\"ihme_loc_id\",\n",
    "             \"sex\",\"sex_issue\",\"age_start\",\"age_end\",\"age_group_id\",\"age_demographer\",\"age_issue\",\n",
    "             \"specificity\",\"note_modeler\",\"visit_type\",\"group_review\",\"group\",\"year_start\",\"year_end\",\n",
    "             \"mean\",\"cases\",\"sample_size\",\"measure\",\"measure_issue\",\"uncertainty_type_value\",\n",
    "             \"design_effect\",\"seq\",\"cv_1_month_recall\",\"smaller_site_unit\",\"modelable_entity_name\",\n",
    "             \"source_type\",\"variable\",\"cv_survey\",\"extractor\",\"cv_whs\",\n",
    "             \"unit_value_as_published\",\"page_num\",\"true_recall\",\"measure_adjustment\",\"response_rate\",\n",
    "             \"site_memo\",\"is_outlier\",\"uncertainty_type\",\n",
    "             \"case_definition\",\"cv_mics\",\"cv_12_month_recall\",\"cv_marketscan\",\n",
    "             \"upper\",\"lower\",\"note_SR\",\"data_sheet_filepath\",\n",
    "             \"modelable_entity_id\",\"recall_type\",\"recall_type_value\",\"effective_sample_size\",\n",
    "             \"table_num\",\"underlying_nid\",\"case_diagnostics\",\n",
    "             \"representative_name\",\"urbanicity_type\",\"sampling_type\",\"case_name\",\"standard_error\",\n",
    "             \"field_citation_value\",\"unit_type\",\"year_issue\",\"file_path\",\n",
    "             \"underlying_field_citation_value\",\"cv_sick\",\"assign\",\"location_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional file cleanup\n",
    "for_split = collect_data_all.copy()\n",
    "for_split['age_diff'] = for_split['age_end'] - for_split['age_start']\n",
    "both_sex = for_split[for_split.sex == 'both']\n",
    "both_sex_wide_age = both_sex[both_sex.age_diff >= 25]\n",
    "both_sex_narrow_age = both_sex[both_sex.age_diff < 25]\n",
    "male_female = for_split[for_split.sex != 'both']\n",
    "mf_wide_age = male_female[male_female.age_diff >= 25]\n",
    "mf_narrow_age = male_female[male_female.age_diff < 25]\n",
    "both_sex_narrow_age['specificity'] = 'age'\n",
    "mf_wide_age['specificity'] = 'sex'\n",
    "for_split = pd.concat([both_sex_wide_age, both_sex_narrow_age, mf_wide_age, mf_narrow_age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_split.sex.replace(\"male\", \"Male\", inplace = True)\n",
    "for_split.sex.replace(\"female\", \"Female\", inplace = True)\n",
    "for_split.sex.replace(\"both\", \"Both\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_split['seq'] = range(1, len(for_split) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_split.measure.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file of post-processing/prep, pre-splitting, pre-xwalk version of data\n",
    "for_split.to_csv('FILEPATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in sex-split file here\n",
    "sex_split_df = pd.read_csv('FILEPATH')\n",
    "# Check to make sure only M/F now\n",
    "sex_split_df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files for crosswalk\n",
    "sex_split_df.loc[(sex_split_df.cv_12_month_recall == 1) & (sex_split_df.cv_survey == 1) & (sex_split_df.visit_type.isin(['ip_avg']))].to_csv('FILEPATH')\n",
    "sex_split_df.loc[(sex_split_df.cv_12_month_recall == 1) & (sex_split_df.visit_type.isin(['ip_frac']))].to_csv('FILEPATH')\n",
    "sex_split_df.loc[(sex_split_df.cv_1_month_recall == 1) & (sex_split_df.visit_type.isin(['ip_frac']))].to_csv('FILEPATH')\n",
    "sex_split_df.loc[sex_split_df.cv_survey == 0].to_csv('FILEPATH')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
