"""Module for squeezing results into an envelope.

The envelope starts with _all_star.nc in the hat_star_dot directory and is generated by
squeezing children causes into their parent envelopes.

By running `python squeeze.py --parent-cause <acause> --squeeze-version
<squeeze-version> --star-version <star-version>`, the parent acause will act as
the envelope to squeeze its children causes into and must
already be in the FILEPATH directory.
The one exception to this is if <acause> is "_all", in which is it
moved from the hat_star_dot/<star-version> directory into the
FILEPATH directory to begin the squeezing process.

The things being squeezed are the ``*_star.nc`` files from the hat_star_dot
directory and are saved in the FILEPATH directory as a
separate mortality or yld version.

The number of draws of the ``*_star.nc`` files must match the number of draws of
the _all_star.nc file, and subsequently the resulting squeezed mortality or
ylds in the FILEPATH directory must have the same number of draws.
"""

from typing import List, Optional

import numpy as np
import pandas as pd
import xarray as xr
from fhs_lib_database_interface.lib.constants import DimensionConstants
from fhs_lib_file_interface.lib.version_metadata import FHSFileSpec, VersionMetadata
from fhs_lib_file_interface.lib.versioning import validate_versions_scenarios_listed
from fhs_lib_file_interface.lib.xarray_wrapper import open_xr_scenario, save_xr_scenario
from fhs_lib_year_range_manager.lib.year_range import YearRange
from tiny_structured_logger.lib import fhs_logging

from fhs_pipeline_mortality.lib import get_fatal_causes
from fhs_pipeline_mortality.lib.intercept_shift import intercept_shift_draws

logger = fhs_logging.get_logger()

FLOOR = 1e-28


def squeeze(
    parent_cause: str,
    star_version: VersionMetadata,
    squeeze_version: VersionMetadata,
    past_version: Optional[VersionMetadata],
    gbd_round_id: int,
    input_space: str,
    years: YearRange,
    output_scenario: Optional[int],
    dryrun: bool = False,
    intercept_shift: bool = False,
) -> None:
    """Main method for squeezing.

    Makes sure the sum of the parent_cause's children is equal to the parent
    cause's estimates, then saves the squeezed child cause results.

    Args:
        parent_cause (str): the acause whose estimates used as the envelope
            which its child causes are squeezed into.
        star_version (VersionMetadata): the version of mortality with ARIMAed residuals
            being squeezed.
        squeeze_version (VersionMetadata): the mortality or yld version the squeezed
            results will be saved as. The parent_cause envelope will
            be of this squeeze_version.
        past_version (VersionMetadata): past mortality version to intercept shift to.
        gbd_round_id (int): numeric id of gbd round.
        input_space (str): space the input data is saved in e.g. log.
        years (YearRange): the years to run.
        outptu_scenario (Optional[int]): The output scenario if running in single-scenario
            mode.
        dryrun (bool): When True, don't write anything, just do calculations and print
            what files would be written. Defaults to False.
        intercept_shift (bool): (Test only) When True, intercept-shift the results of
            scaling so that the last-past year matches data in ``past_version``. Defaults
            to True. (This is set to False in unit-testing to isolate and test certain
            subsystems.)

    Raises:
        ValueError: if the parent data shape != the child data shape
    """
    versions_to_validate = [star_version, squeeze_version]
    if past_version:
        versions_to_validate.append(past_version)

    validate_versions_scenarios_listed(
        versions=versions_to_validate,
        output_versions=[squeeze_version],
        output_scenario=output_scenario,
    )

    children_sum = xr.DataArray(name="Empty xr.DataArray")
    children_acauses = get_children_acauses(parent_cause, gbd_round_id)
    logger.debug(f"Children acauses are: {children_acauses}")

    if input_space == "log":
        suffix = "_star"
    elif input_space == "normal":
        suffix = ""
    else:
        err_msg = "input_space argument not recognized. Options are `log` or `normal`."
        raise ValueError(err_msg)

    for child_acause in children_acauses:
        child_data = get_y_star(child_acause, star_version, input_space, suffix)
        children_sum = _update_children_sum(children_sum, child_data)

    parent_data = open_xr_scenario(FHSFileSpec(squeeze_version, f"{parent_cause}.nc"))
    parent_data.load()

    if (
        parent_data.coords[DimensionConstants.DRAW].shape
        != children_sum.coords[DimensionConstants.DRAW].shape
    ):
        raise ValueError("The parent and child don't have the same number of draws.")

    # Calculate ratio on means, not draws.
    parent_data_mean = parent_data.mean("draw")
    children_sum_mean = children_sum.mean("draw")
    ratio = parent_data_mean / children_sum_mean

    # Loop through and multiply all children by ratio, saving results.
    for child in children_acauses:
        logger.info(f"Squeezing {child}")
        squeezed_child = _multiply_children_by_ratio(
            star_version, child, ratio, suffix, input_space
        )

        _save_squeezed_child_result(
            squeezed_child,
            child,
            gbd_round_id,
            years,
            squeeze_version,
            past_version,
            dryrun,
            intercept_shift,
        )


def _save_squeezed_child_result(
    squeezed_child: xr.DataArray,
    child: str,
    gbd_round_id: int,
    years: YearRange,
    squeeze_version: VersionMetadata,
    past_version: Optional[VersionMetadata],
    dryrun: bool,
    intercept_shift: bool,
) -> None:
    """Save squeezed child result."""
    # The intercept shift was added to fix the t+1 introduced by updating the
    # malaria to lvl2 cause in squeeze. Now the t+1 has been resolved by
    # updating the malaria to lvl2 cause from stage 2 before ARIMA and create
    # the new _ntd without malaria cause. Set intercept shift to False.
    if intercept_shift:
        squeezed_child = squeezed_child.dropna(how="all", dim="sex_id")
        log_squeezed_child = np.log(squeezed_child + FLOOR)
        log_squeezed_child_shifted = intercept_shift_draws(
            preds=log_squeezed_child,
            acause=child,
            past_version=past_version,
            gbd_round_id=gbd_round_id,
            years=years,
            draws=len(log_squeezed_child.draw.values),
            shift_function=unordered_draw_intercept_shift,
        )
        squeezed_child = np.exp(log_squeezed_child_shifted)

    # fill NaNs with 0s
    squeezed_child = squeezed_child.fillna(0.0)

    out_path = FHSFileSpec(squeeze_version, f"{child}.nc")

    if dryrun:
        logger.info(f"(Dry run) Not writing to {out_path}")
    else:
        logger.info(f"Writing to {out_path}")
        save_xr_scenario(squeezed_child, out_path, metric="rate", space="identity")


def _remove_acause_dim(da: xr.DataArray) -> xr.DataArray:
    if DimensionConstants.ACAUSE in da.coords:
        da = da.drop_vars(DimensionConstants.ACAUSE)
    return da.squeeze()


def _multiply_children_by_ratio(
    star_version: VersionMetadata,
    child: str,
    ratio: xr.DataArray,
    suffix: str,
    input_space: str,
) -> xr.DataArray:
    """Multiply all children by ratio, saving results."""
    path_in = FHSFileSpec(star_version, f"{child}{suffix}.nc")
    child_input_data = open_xr_scenario(path_in)
    if input_space == "log":
        child_data = np.exp(child_input_data)
    else:
        child_data = child_input_data

    child_data = _remove_acause_dim(child_data)

    # for single-sex causes, add nans to create dimension sex_id
    child_data = makeup_array(child_data)

    squeezed_child = child_data * ratio

    return squeezed_child


def _update_children_sum(
    children_sum: xr.DataArray,
    child_data: xr.DataArray,
) -> xr.DataArray:
    """Update children sum based on acause and sex.

    For causes with coord `acause`, drop `acause`.
    And for ntd causes (the dataset does not have coord `acause`), squeeze the causes,
    then add nans for single-sex causes.
    Lastly, broadcast child data array against children sum data array.
    """
    child_data = _remove_acause_dim(child_data)

    # for single-sex causes, add nans to create dimension sex_id
    child_data = makeup_array(child_data)

    if children_sum.name == "Empty xr.DataArray":
        children_sum = child_data
    else:
        children_broadcast = xr.broadcast(children_sum, child_data)
        children_broadcast = [data.fillna(0.0) for data in children_broadcast]
        children_sum = sum(children_broadcast)
        children_sum.load()

    return children_sum


def unordered_draw_intercept_shift(
    modeled_data: xr.DataArray,
    past_data: xr.DataArray,
    past_end_year_id: int,
) -> xr.DataArray:
    """Intercept shift by the last past year in log space.

    Args:
        modeled_data (xr.DataArray): FHS estimates
        past_data (xr.DataArray): Past estimates from GBD
        past_end_year_id (int): Last year of past data

    Returns:
        xr.DataArray: Shifted estimates
    """
    past_data = past_data.sel(**{DimensionConstants.YEAR_ID: past_end_year_id}, drop=True)
    coords = {DimensionConstants.YEAR_ID: past_end_year_id}
    if DimensionConstants.SCENARIO in modeled_data:
        coords = dict(
            coords, **{DimensionConstants.SCENARIO: DimensionConstants.REFERENCE_SCENARIO}
        )
    modeled_last_past_year = modeled_data.sel(**coords, drop=True)
    diff = modeled_last_past_year - past_data
    shifted_data = modeled_data - diff
    return shifted_data


def makeup_array(child_data: xr.DataArray) -> xr.DataArray:
    """Add dimension sex_id for single_sex causes.

    Args:
        child_data (xr.DataArray): child data with single_sex causes

    Returns:
        xr.DataArray: child data with opposite_sex data
    """
    if DimensionConstants.SEX_ID not in child_data.dims:
        na_array = child_data.copy()
        sex_value = child_data[DimensionConstants.SEX_ID].values
        if sex_value == 1:
            opposite_sex = 2
        else:
            opposite_sex = 1
        na_array = na_array * 0.0
        na_array[DimensionConstants.SEX_ID] = opposite_sex
        child_data = xr.concat([child_data, na_array], dim=DimensionConstants.SEX_ID)
        return child_data
    return child_data


def _drop_measure(data: xr.DataArray) -> xr.DataArray:
    """Helper function as a preprocessing step when calling xarray's open_mfdataset function.

    In order to make sure all the dimensions are compatible across dataarrays.

    Args:
        data (xr.DataArray): the dataarray to preprocess

    Returns:
        xr.DataArray: the original data with the measure dimension dropped
            if it originally existed.
    """
    try:
        data = data.drop_vars("measure")
    except ValueError:
        pass
    try:
        data.rename({"ds = da.to_dataset": "value"})
    except ValueError:
        pass
    return data


def get_y_star(
    acause: str,
    star_version: VersionMetadata,
    input_space: str,
    suffix: str,
    draws: bool = True,
) -> xr.DataArray:
    """Gets estimates of means and modeled residuals (``*_star.nc`` file) for a cause.

    Results are returned in normal space regardless of the input space.

    Args:
        acause_list (str): acause to get data for.
        star_version (VersionMetadata): the version whose data is being read.
        input_space (str): "log" or "normal" as describes the space of the data; it will be
            transformed to normal space.
        suffix (str): a str to be appended to each cause name to produce the file names.
        draws (bool): if False, the mean over the draws dimension is used.

    Returns:
        xr.DataArray: data in regular rate space which contains a dimension for acause.
    """
    input_data = open_xr_scenario(FHSFileSpec(star_version, f"{acause}{suffix}.nc"))

    if not draws:
        input_data = input_data.mean(DimensionConstants.DRAW)  # take mean to get rid of draws

    if input_space == "log":
        y_star = np.exp(input_data)  # exponentiate into normal space
    elif input_space == "normal":
        y_star = input_data
    return y_star


def get_children_acauses(acause: str, gbd_round_id: int) -> List[str]:
    """Gets the children acauses for a given acause.

    Does not include any that are in the CAUSES_TO_EXCLUDE list

    Args:
        acause (str): the acause of the cause to find children of.
        gbd_round_id (int): numeric id of gbd round.

    Returns:
        List[str]: the children acauses of the input acause.
    """
    fatal_causes = get_fatal_causes.get_fatal_causes_df(gbd_round_id)[
        [
            DimensionConstants.ACAUSE,
            DimensionConstants.CAUSE_ID,
            DimensionConstants.PARENT_ID_COL,
        ]
    ]
    return get_children_acauses_from_dataframe(acause, fatal_causes)


def get_children_acauses_from_dataframe(
    acause: str, cause_hierarchy: pd.DataFrame
) -> List[str]:
    """Get the children of the given acause from a dataframe representing the hierarchy."""
    cause_id = cause_hierarchy[cause_hierarchy.acause == acause].cause_id.values[0]
    all_children = cause_hierarchy.query(f"parent_id == {cause_id}")[
        DimensionConstants.ACAUSE
    ].values
    children = [child for child in all_children if child not in ("_all", "_none")]
    return children


def copy_all_star(
    star_version: VersionMetadata,
    squeeze_version: VersionMetadata,
    input_space: str,
    output_scenario: Optional[int],
    dryrun: bool = False,
) -> None:
    """Copies _all data from star_version into squeeze_version, possibly translating.

    If input_space is log, the data is converted from log rate space into regular rate space
    before being saved. In that case, too, the file will be found in _all_star.nc rather than
    _all.nc

    Args:
        star_version (str): the version of mortality with ARIMAed residuals
        squeeze_version (str): the version of mortality with squeezed results
        input_space (str): space the input data is saved in.
        root_dir (str): FHS file system root directory. Where the input data is stored.
        output_scenario (Optional[int]): The output scenario if running in single scenario mode
        dryrun (bool): flag for dry runs
    """
    versions_to_validate = [star_version, squeeze_version]

    validate_versions_scenarios_listed(
        versions=versions_to_validate,
        output_versions=[squeeze_version],
        output_scenario=output_scenario,
    )

    if input_space == "log":
        suffix = "_star"
    else:
        suffix = ""
    all_input_data = open_xr_scenario(FHSFileSpec(star_version, f"_all{suffix}.nc"))

    if input_space == "log":
        all_data = np.exp(all_input_data)
    else:
        all_data = all_input_data

    out_path = FHSFileSpec(squeeze_version, "_all.nc")
    if dryrun:
        logger.info(f"(Dry run) Not writing to {out_path}")
    else:
        logger.info(f"Writing to {out_path}")
        save_xr_scenario(
            all_data,
            out_path,
            metric="rate",
            space="identity",
        )
